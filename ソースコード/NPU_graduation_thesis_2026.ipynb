{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "dRGk5iIUHn7D"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n39lKZfjfsB-",
        "outputId": "d7fa26ab-31cd-4e2a-9dc3-94f0dc0fec98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "### GoogleDriveへの接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **以下、データ加工（反復写像図の作成）**"
      ],
      "metadata": {
        "id": "dRGk5iIUHn7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 必要ライブラリのインポート\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter # フィルター用\n"
      ],
      "metadata": {
        "id": "YsGYevcejtG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Google driveにあるファイルのパス情報\n",
        "# cuff less blood pressure estimationデータセットダウンロード\n",
        "drive_file1 = \"/content/drive/MyDrive/cuff_less_blood_pressure_matlabfiles/Part_1.mat\"\n",
        "drive_file2 = \"/content/drive/MyDrive/cuff_less_blood_pressure_matlabfiles/Part_2.mat\"\n",
        "drive_file3 = \"/content/drive/MyDrive/cuff_less_blood_pressure_matlabfiles/Part_3.mat\"\n",
        "drive_file4 = \"/content/drive/MyDrive/cuff_less_blood_pressure_matlabfiles/Part_4.mat\"\n",
        "\n",
        "drive_files = [drive_file1, drive_file2, drive_file3, drive_file4]"
      ],
      "metadata": {
        "id": "NFXvUQSibCOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 全データ読み込み\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# 結果を格納するリスト\n",
        "data_list = []\n",
        "\n",
        "# matファイルからデータを読み込み、numpy形式で全データをdata_listに格納\n",
        "for idx, drive_file in enumerate(drive_files):\n",
        "  with h5py.File(drive_file, \"r\") as f:\n",
        "      print(list(f.keys()))  # e.g. ['#refs#', 'Part_1']\n",
        "      data_group = f[f'Part_{idx + 1}']\n",
        "      print(data_group.shape,\"data_group\")\n",
        "      # ファイル構造＝(3000，1）3000はデータ件数\n",
        "\n",
        "     # すべてのセルを読み込む\n",
        "      for i in range(data_group.shape[0]):\n",
        "          ref = data_group[i][0]     # セルの参照を取得\n",
        "          dataset = f[ref]           # 実データにアクセス\n",
        "          arr = dataset[:]           # NumPy配列に変換\n",
        "          arr = arr.T                # 転置\n",
        "          data_list.append(arr)      # リストに格納\n",
        "\n",
        "\n",
        "\n",
        "# 例として最初のデータの形状と内容を表示\n",
        "print(f\"Total records: {len(data_list)}\")\n",
        "print(f\"Shape of data_list[0].shape: {data_list[0].shape}\")\n",
        "print(data_list[0])"
      ],
      "metadata": {
        "id": "y-cCux1gLqiV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### バターワースフィルタ\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "def butter_bandpass_sos(lowcut, highcut, fs, order=4):\n",
        "    \"\"\"\n",
        "    2次節(SOS)でバターワースバンドパスを設計して返す。\n",
        "    lowcut, highcut: Hz\n",
        "    fs: サンプリング周波数 (Hz)\n",
        "    order: フィルタ次数（総次数、ここでは4を指定すると4次）\n",
        "    \"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    if not (0 < low < high < 1):\n",
        "        raise ValueError(f\"lowcut/highcut が不正です (low={lowcut}, high={high}, fs={fs})\")\n",
        "    # SOS 出力で設計（数値安定性が良い）\n",
        "    sos = signal.butter(order, [low, high], btype='band', output='sos')\n",
        "    return sos\n",
        "\n",
        "def apply_zero_phase_sosfilt(sos, data):\n",
        "    \"\"\"\n",
        "    sos を使ってゼロ位相（双方向）フィルタリングを行う。\n",
        "    入力が短すぎる場合は sosfilt（片方向）で代替する。\n",
        "    \"\"\"\n",
        "    # sosfiltfilt のパディング長は内部で計算されるが、\n",
        "    # scipy の filtfilt と同様 padlen が必要になることがあるためチェック\n",
        "    try:\n",
        "        # sosfiltfilt が利用可能ならこれを使うのが最も安全\n",
        "        y = signal.sosfiltfilt(sos, data)\n",
        "    except Exception as e:\n",
        "        # 短い信号やバージョン差異で失敗したら sosfilt に落とす（位相は残る）\n",
        "        # その場合、前後反転して2回かける手法（簡易ゼロ位相信号復元）でも試せるが、\n",
        "        # ここでは単純に sosfilt を返す\n",
        "        y = signal.sosfilt(sos, data)\n",
        "    return y\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut=0.5, highcut=8.0, fs=100.0, order=4):\n",
        "    \"\"\"\n",
        "    簡易ラッパー：データ配列に対して 0.5-8Hz (default) の4次バターワースバンドパスを適用。\n",
        "    data: 1D numpy array\n",
        "    fs: サンプリング周波数 (Hz)\n",
        "    \"\"\"\n",
        "    sos = butter_bandpass_sos(lowcut, highcut, fs, order=order)\n",
        "    return apply_zero_phase_sosfilt(sos, data)\n"
      ],
      "metadata": {
        "id": "REAZTCJ3K_h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### データセット平滑化(PPGをバターワースフィルタへ)\n",
        "fs = 125.0\n",
        "for idx, arr in enumerate(data_list):\n",
        "  smoothed_ppg = butter_bandpass_filter(arr[0], lowcut=0.5, highcut=8.0, fs=fs, order=4)\n",
        "  data_list[idx][0] = smoothed_ppg"
      ],
      "metadata": {
        "id": "2wtHWmStLZjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 速度脈波、加速度脈波作成\n",
        "# ステップサイズ（h）\n",
        "\n",
        "fs = 125.0 # サンプリング周波数\n",
        "\n",
        "t = 1 / fs\n",
        "vppg_list_before = []\n",
        "appg_list_before = []\n",
        "\n",
        "for idx, arr in enumerate(data_list):\n",
        "  vppg_list_before.append(np.gradient(arr[0], t))\n",
        "  appg_list_before.append(np.gradient(vppg_list_before[idx], t))\n",
        "\n",
        "print(len(vppg_list_before))\n",
        "print(len(appg_list_before))\n",
        "print(vppg_list_before[0].shape)\n",
        "print(appg_list_before[0].shape)\n",
        "#data_list.append(np.array(vppg_list_before))\n",
        "#data_list.append(np.array(appg_list_before))\n",
        "\n",
        "#print(data_list.shape)"
      ],
      "metadata": {
        "id": "nRQ8AZ1XTEaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### データリストの分割（180秒（fs*180)ごとに分割し、新しくリストに格納）\n",
        "\n",
        "chunk_size = 125 * 180  # 分割チャンクサイズ（180ごと）\n",
        "\n",
        "ppg_data_list_row = []  # ppgデータ群\n",
        "abp_data_list_row = []  # sbpデータ群\n",
        "\n",
        "vppg_data_list_row = [] # vppgデータ群\n",
        "appg_data_list_row = [] # appgデータ群\n",
        "\n",
        "# data_listをチャンクサイズで分割\n",
        "for record_idx, arr in enumerate(data_list):\n",
        "    # 何チャンク作れるか\n",
        "    n_chunks = arr.shape[1] // chunk_size\n",
        "\n",
        "    if(n_chunks == 0): # データの長さがチャンク数を下回る場合はスキップ\n",
        "      continue\n",
        "\n",
        "    for chunk_idx in range(n_chunks):\n",
        "        start = chunk_idx * chunk_size\n",
        "        end   = start + chunk_size\n",
        "\n",
        "        # 1 行目が ppg、2 行目が abp\n",
        "        ppg = arr[0, start:end]\n",
        "        abp = arr[1, start:end]\n",
        "        vppg = vppg_list_before[record_idx][start:end]\n",
        "        appg = appg_list_before[record_idx][start:end]\n",
        "\n",
        "        ppg_data_list_row.append(ppg)\n",
        "        abp_data_list_row.append(abp)\n",
        "        vppg_data_list_row.append(vppg)\n",
        "        appg_data_list_row.append(appg)\n",
        "\n",
        "# 確認\n",
        "print(f\"ppgチャンク数: {len(ppg_data_list_row)}\")\n",
        "print(f\"sbpチャンク数: {len(abp_data_list_row)}\")\n",
        "print(f\"vppgチャンク数: {len(vppg_data_list_row)}\")\n",
        "print(f\"appgチャンク数: {len(appg_data_list_row)}\")\n",
        "\n",
        "# 確認\n",
        "print(f\"全レコード数：{len(ppg_data_list_row)}\")\n",
        "print(f\"全レコード数：{len(abp_data_list_row)}\")\n",
        "print(f\"全レコード数：{len(vppg_data_list_row)}\")\n",
        "print(f\"全レコード数：{len(appg_data_list_row)}\")\n",
        "print(f\"ppg_data_list_row[0].shape = {ppg_data_list_row[0].shape}\")\n",
        "print(f\"abp_data_list_row[0].shape = {abp_data_list_row[0].shape}\")\n",
        "print(f\"vppg_data_list_row[0].shape = {vppg_data_list_row[0].shape}\")\n",
        "print(f\"appg_data_list_row[0].shape = {appg_data_list_row[0].shape}\")\n",
        "print(f\"最初のデータ ppg ={ppg_data_list_row[:10]}\")\n",
        "print(f\"最初のデータ abp ={abp_data_list_row[:10]}\")\n",
        "print(f\"最初のデータ vppg ={vppg_data_list_row[:10]}\")\n",
        "print(f\"最初のデータ appg ={appg_data_list_row[:10]}\")"
      ],
      "metadata": {
        "id": "mkYCr-fn7JKY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### データを正しく読み込めているか確認\n",
        "# データセットPart1の最初のレコード10列目まで表示\n",
        "print(f\"最初のデータ ppg ={ppg_data_list_row[0][:10]}\")\n",
        "print(f\"最初のデータ abp ={abp_data_list_row[0][:10]}\")"
      ],
      "metadata": {
        "id": "i3sIpDIScU8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SBP推定\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# サンプリング周波数（cuff less blood pressure estimation データセット）\n",
        "fs = 125\n",
        "\n",
        "# ピークを見つける\n",
        "def find_all_peaks(abp_data_list):\n",
        "    peaks_list = []\n",
        "    # 間隔 (0.5秒ごと)\n",
        "    distance = int(fs * 0.5)\n",
        "\n",
        "    for abp in abp_data_list:\n",
        "      n = len(abp)\n",
        "      t = np.arange(n) / fs\n",
        "      abp_median = np.median(abp)\n",
        "      abp_min = np.min(abp)\n",
        "      delta = abp_median - abp_min\n",
        "\n",
        "      peaks, props = find_peaks(abp,distance=distance, prominence= delta)\n",
        "      #peaks,props = find_peaks(abp, height=70, distance=distance,prominence=10.0,width=10)\n",
        "      peaks_list.append(peaks)\n",
        "    return peaks_list\n",
        "\n",
        "# SBP推定 (前ピークの平均値)\n",
        "def calculate_sbp(peaks_list,abp_data_list):\n",
        "    sbp_data_list = []\n",
        "\n",
        "    for id,peaks in enumerate(peaks_list):\n",
        "      sbp_mean = np.mean(abp_data_list[id][peaks])\n",
        "      sbp_data_list.append(sbp_mean)\n",
        "    return sbp_data_list\n",
        "\n",
        "# DBP推定（ピーク間の最小値）\n",
        "def find_all_dbp(peaks_list,abp_data_list):\n",
        "  dbp_data_mean_list = []\n",
        "  for id,peaks_sbp in enumerate(peaks_list):\n",
        "    dbp_data_all_list = []\n",
        "    # 最初のピークから最後のピークまで繰り返す\n",
        "    for i in range(len(peaks_sbp) - 1):\n",
        "    # 連続する2つのSBPピークのインデックスを取得\n",
        "      start_index = peaks_sbp[i]\n",
        "      end_index = peaks_sbp[i+1]\n",
        "\n",
        "      # 2つのピーク間の信号セグメントを抽出\n",
        "      segment = abp_data_list[id][start_index : end_index + 1] # +1 は end_index を含めるため\n",
        "\n",
        "      # セグメント内の最小値を見つける\n",
        "      dbp_segment = np.min(segment)\n",
        "      dbp_data_all_list.append(dbp_segment)\n",
        "\n",
        "    dbp_data_mean_list.append(np.mean(dbp_data_all_list))\n",
        "\n",
        "  return dbp_data_mean_list\n",
        "\n",
        "# ピークのidリスト\n",
        "peaks_list = find_all_peaks(abp_data_list_row)\n",
        "# 各ピークの平均値（SBP)\n",
        "sbp_data_list_row = calculate_sbp(peaks_list, abp_data_list_row)\n",
        "# DBP（ピーク間の最小値）\n",
        "dbp_data_list_row = find_all_dbp(peaks_list, abp_data_list_row)\n",
        "\n",
        "# 確認\n",
        "print(len(sbp_data_list_row))\n",
        "print(len(dbp_data_list_row))\n",
        "print(sbp_data_list_row[:10])\n",
        "print(dbp_data_list_row[:10])\n"
      ],
      "metadata": {
        "id": "T4gypEBGPLZE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 異常値削除\n",
        "remove_idx_list = []\n",
        "for idx, (sbp, dbp) in enumerate(zip(sbp_data_list_row, dbp_data_list_row)):\n",
        "  ranges = abs(sbp - dbp) # 絶対値を使用\n",
        "  if sbp < 80 or sbp > 190:\n",
        "    remove_idx_list.append(idx)\n",
        "\n",
        "  elif dbp < 50 or dbp > 120:\n",
        "    remove_idx_list.append(idx)\n",
        "\n",
        "  elif ranges < 20 or ranges > 120:\n",
        "    remove_idx_list.append(idx)\n",
        "\n",
        "print(len(remove_idx_list))\n",
        "remove_idx_list = list(set(remove_idx_list))\n",
        "remove_idx_list.sort()\n",
        "print(len(remove_idx_list))\n",
        "print(remove_idx_list[:10])\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "# 異常値をリストから削除\n",
        "print(f'削除前PPG{len(ppg_data_list_row)}')\n",
        "ppg_data_list = [item for index, item in enumerate(ppg_data_list_row) if index not in remove_idx_list]\n",
        "print(f'削除後PPG{len(ppg_data_list)}')\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(f'削除前ABP{len(abp_data_list_row)}')\n",
        "abp_data_list = [item for index, item in enumerate(abp_data_list_row) if index not in remove_idx_list]\n",
        "print(f'削除後ABP{len(abp_data_list)}')\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(f'削除前VPPG{len(vppg_data_list_row)}')\n",
        "vppg_data_list = [item for index, item in enumerate(vppg_data_list_row) if index not in remove_idx_list]\n",
        "print(f'削除後VPPG{len(vppg_data_list)}')\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(f'削除前APPG{len(appg_data_list_row)}')\n",
        "appg_data_list = [item for index, item in enumerate(appg_data_list_row) if index not in remove_idx_list]\n",
        "print(f'削除後APPG{len(appg_data_list)}')\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(f'削除前sbp{len(sbp_data_list_row)}')\n",
        "sbp_data_list = [item for index, item in enumerate(sbp_data_list_row) if index not in remove_idx_list]\n",
        "print(f'削除後sbp{len(sbp_data_list)}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RXgfiHVw6cGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### sbp140mmhg未満と以上で分ける\n",
        "above140_idx_list = []\n",
        "below140_idx_list = []\n",
        "\n",
        "for idx, sbp in enumerate(sbp_data_list):\n",
        "  if sbp >= 140:\n",
        "    above140_idx_list.append(idx)\n",
        "  else:\n",
        "    below140_idx_list.append(idx)\n",
        "\n",
        "print(len(above140_idx_list))\n",
        "print(len(below140_idx_list))\n",
        "print(above140_idx_list[:10])\n",
        "print(below140_idx_list[:10])"
      ],
      "metadata": {
        "id": "WRPih7QeH9TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 反復写像図作成　本物\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def make_return_pairs(data, fs, tau_seconds, offset=0):\n",
        "    \"\"\"\n",
        "    τ秒ごとに離散サンプリングして対を作る。\n",
        "    - data: 1D array-like (list or np.array)\n",
        "    - fs: サンプリング周波数 [Hz]\n",
        "    - tau_seconds: 遅延時間 τ [秒]\n",
        "    - offset: 0 <= offset < tau_samples。開始インデックスのオフセット（データを増やしたい時に複数のオフセットで呼ぶ）\n",
        "    Returns (M_n, M_n_plus_1) as numpy arrays.\n",
        "    \"\"\"\n",
        "    if tau_seconds <= 0:\n",
        "        raise ValueError(\"tau_seconds must be > 0\")\n",
        "\n",
        "    tau_samples = int(tau_seconds * fs) #　間隔t=0.1なら12個　小数点以下切り捨て\n",
        "\n",
        "    if tau_samples <= 0:\n",
        "        raise ValueError(\"tau_seconds * fs < 0.5 -> tau_samples == 0 になりました。fs と tau_seconds を確認してください。\")\n",
        "\n",
        "    if offset < 0 or offset >= tau_samples:\n",
        "        raise ValueError(\"offset must satisfy 0 <= offset < tau_samples\")\n",
        "\n",
        "    N = data.size\n",
        "    # k = 0,1,... でインデックス = offset + k * tau_samples が有効な範囲\n",
        "    last_valid_start = N - tau_samples - offset\n",
        "    if last_valid_start < 0:\n",
        "        # 十分な長さがない\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    k_indices = np.arange(offset, N - tau_samples, tau_samples)\n",
        "    M_n = data[k_indices]\n",
        "    M_n_plus_1 = data[k_indices + tau_samples]\n",
        "    #print(M_n[:5])\n",
        "    #print(M_n_plus_1[:5])\n",
        "    return M_n, M_n_plus_1\n",
        "\n",
        "\n",
        "def plot_return_map_decimated(M_n, M_n_plus_1, out_path, class_name, idx, fig, ax, type):\n",
        "    \"\"\"\n",
        "    与えられたペアを散布図として保存する（余白ゼロ、軸非表示）。\n",
        "    - M_n, M_n_plus_1: numpy arrays\n",
        "    - out_path: 保存ディレクトリ\n",
        "    - fname: ファイル名（拡張子含む例: 'above_idx_12.png'）\n",
        "    - figsize: inch 単位（例 2.24inch * 100dpi = 224px）\n",
        "    - dpi: 保存時の DPI\n",
        "    \"\"\"\n",
        "    #os.makedirs(out_path, exist_ok=True)\n",
        "    #fig, ax = plt.subplots(figsize=figsize)\n",
        "    if M_n.size == 0:\n",
        "        raise ValueError(\"M_n.size == 0 になりました。\") # エラー投げ\n",
        "        return\n",
        "\n",
        "    vmin = np.min(M_n)\n",
        "    vmax = np.max(M_n_plus_1)\n",
        "\n",
        "    #ax.scatter(M_n, M_n_plus_1, s=1, alpha=0.7, marker='.')\n",
        "    ax.plot(M_n, M_n_plus_1, '.', markersize=0.5, alpha=1)\n",
        "\n",
        "    # ▷ 軸の設定（スケールと範囲）\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlim([vmin, vmax])\n",
        "    ax.set_ylim([vmin, vmax])\n",
        "\n",
        "    ax.set_axis_off()\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
        "    plt.savefig(f'{out_path}/{class_name}_type_{type}_idx_{idx}.png')\n",
        "\n",
        "    ax.cla()    #グラフ（軸）をリセット\n",
        "\n",
        "# ループにより脈波データ集を反復写像図に\n",
        "tau = 0.1 # タウ\n",
        "\n",
        "root_path = f'/content/反復写像図_standard=sbp140_len=22500_t={tau}'\n",
        "above_path = f'/content/反復写像図_standard=sbp140_len=22500_t={tau}/above_sbp140'\n",
        "below_path = f'/content/反復写像図_standard=sbp140_len=22500_t={tau}/below_sbp140'\n",
        "\n",
        "above_class = 'above_sbp'\n",
        "below_class = 'below_sbp'\n",
        "\n",
        "import os\n",
        "os.makedirs(root_path, exist_ok=True)\n",
        "os.makedirs(above_path, exist_ok=True)\n",
        "os.makedirs(below_path, exist_ok=True)\n",
        "\n",
        "fs = 125 # サンプリング周波数\n",
        "fig, ax = plt.subplots(figsize=(2.24, 2.24))     # figure, axis作成\n",
        "\n",
        "# above140グループの画像作成\n",
        "for idx in tqdm(above140_idx_list):\n",
        " # ノーマル脈波を変換する場合（コメント解除する）\n",
        " #M_n, M_n_plus_1 = make_return_pairs(ppg_data_list[idx], fs, tau)\n",
        " #plot_return_map_decimated(M_n, M_n_plus_1, above_path, above_class, idx, fig, ax, \"ppg\")\n",
        "\n",
        " # VPPGを変換する場合\n",
        " #M_n, M_n_plus_1 = make_return_pairs(vppg_data_list[idx], fs, tau)\n",
        " #plot_return_map_decimated(M_n, M_n_plus_1, above_path, above_class, idx, fig, ax, \"vppg\")\n",
        "\n",
        " # APPGを変換する場合\n",
        " M_n, M_n_plus_1 = make_return_pairs(appg_data_list[idx], fs, tau)\n",
        " plot_return_map_decimated(M_n, M_n_plus_1, above_path, above_class, idx, fig, ax, \"appg\")\n",
        "\n",
        "\n",
        "# below140グループの画像作成\n",
        "for idx in tqdm(below140_idx_list):\n",
        " # ノーマル脈波を変換する場合\n",
        " #M_n, M_n_plus_1 = make_return_pairs(ppg_data_list[idx], fs, tau)\n",
        " #plot_return_map_decimated(M_n, M_n_plus_1, below_path, below_class, idx, fig, ax, \"ppg\")\n",
        "\n",
        " # VPPGを変換する場合\n",
        " #M_n, M_n_plus_1 = make_return_pairs(vppg_data_list[idx], fs, tau)\n",
        " #plot_return_map_decimated(M_n, M_n_plus_1, below_path, below_class, idx, fig, ax, \"vppg\")\n",
        "\n",
        " # APPGを変換する場合\n",
        " M_n, M_n_plus_1 = make_return_pairs(appg_data_list[idx], fs, tau)\n",
        " plot_return_map_decimated(M_n, M_n_plus_1, below_path, below_class, idx, fig, ax, \"appg\")\n"
      ],
      "metadata": {
        "id": "rOb_uQtBb9eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 作成したデータセットファイルの確認\n",
        "# ファイル数を調べたいフォルダのパス\n",
        "above_path = \"/content/反復写像図_standard=sbp140_len=22500_t=0.1/above_sbp140\"\n",
        "below_path = \"/content/反復写像図_standard=sbp140_len=22500_t=0.1/below_sbp140\"\n",
        "\n",
        "# フォルダ内の全ファイル名をリスト化\n",
        "above_files = os.listdir(above_path)\n",
        "below_files = os.listdir(below_path)\n",
        "\n",
        "# リストの長さ（ファイル数）を取得\n",
        "above_count = len(above_files)\n",
        "below_count = len(below_files)\n",
        "\n",
        "# ファイル数を確認\n",
        "print(above_count)\n",
        "print(below_count)"
      ],
      "metadata": {
        "id": "H5K7PtDkud43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### zip圧縮\n",
        "# ダウンロードしたいフォルダを zip 圧縮する\n",
        "!zip -r /content/反復写像図_standard=sbp140_len=22500_t=0.1.zip /content/反復写像図_standard=sbp140_len=22500_t=0.1\n",
        "\n"
      ],
      "metadata": {
        "id": "vZUtz65EvhQ9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 圧縮した zip ファイルをダウンロードする\n",
        "from google.colab import files\n",
        "files.download(\"/content/反復写像図_standard=sbp140_len=22500_t=0.1.zip\")"
      ],
      "metadata": {
        "id": "JtK5eCzVxbpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **以下、ConveNeXtによる学習**"
      ],
      "metadata": {
        "id": "jhx2s9eLfX2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインストール\n",
        "!pip install torchviz torchinfo\n",
        "!apt install -y tree\n",
        "!pip install -q tqdm\n",
        "!pip install torch-lr-finder\n",
        "\n",
        "\n",
        "# PyTorchと関連ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch import tensor\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JV8xVJEXfin6",
        "outputId": "b98772bd-0952-47ac-96c5-24df6378f2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchviz) (2.9.0+cu126)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchviz) (3.0.3)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo, torchviz\n",
            "Successfully installed torchinfo-1.8.0 torchviz-0.0.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (159 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting torch-lr-finder\n",
            "  Downloading torch_lr_finder-0.2.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from torch-lr-finder) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-lr-finder) (2.0.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from torch-lr-finder) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-lr-finder) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from torch-lr-finder) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->torch-lr-finder) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.4.1->torch-lr-finder) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=0.4.1->torch-lr-finder) (3.0.3)\n",
            "Downloading torch_lr_finder-0.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Transform定義\n",
        "\n",
        "# 学習用（データ拡張＋正規化）\n",
        "train_transform = transforms.Compose([\n",
        "    # ランダムに切り抜き、224^2にリサイズ\n",
        "    transforms.RandomResizedCrop((224,224),scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),\n",
        "\n",
        "    # Tensor型に変換\n",
        "    transforms.ToTensor(),\n",
        "    # 正規化\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225]),\n",
        "    # ランダムに黒い矩形追加\n",
        "    #transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
        "])\n",
        "\n",
        "# 検証、テスト用（データ拡張なし）\n",
        "val_and_test_transform = transforms.Compose([\n",
        "    #ピクセル数は変えない（224**2）\n",
        "\n",
        "    # Tensor型に変換\n",
        "    transforms.ToTensor(),\n",
        "    # 正規化\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "GofoWyxqgcks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ハイパーパラメータ一覧\n",
        "from enum import StrEnum\n",
        "\n",
        "## タグチメソッド用　調整対象パラメータ\n",
        "# 学習方法\n",
        "class Learning_Type(StrEnum):\n",
        "    Transfer_Learning = \"転移学習\" # 転移学習\n",
        "    Fine_Tuning = \"ファインチューニング\" # ファインチューニング\n",
        "\n",
        "# 学習率\n",
        "lr_1 = 5.00e-6\n",
        "lr_2 = 5.00e-5\n",
        "lr_3 = 1.00e-4\n",
        "\n",
        "# バッチサイズ\n",
        "batch_size_1 = 16\n",
        "batch_size_2 = 32\n",
        "batch_size_3 = 64\n",
        "\n",
        "# エポック数\n",
        "num_epochs_1 = 15\n",
        "num_epochs_2 = 30\n",
        "num_epochs_3 = 45\n",
        "\n",
        "# Stochastic Depth\n",
        "stochastic_depth_1 = 0.2\n",
        "stochastic_depth_2 = 0.4\n",
        "stochastic_depth_3 = 0.6\n",
        "\n",
        "# Weight Decay\n",
        "weight_decay_1 = 1.00e-10\n",
        "weight_decay_2 = 1.00e-8\n",
        "weight_decay_3 = 1.00e-6\n",
        "\n",
        "# サンプル画像\n",
        "class Sample_Type(StrEnum):\n",
        "  PPG = \"PPG\" # ノーマル脈波\n",
        "  VPPG = \"VPPG\" # 速度脈波（一回微分）\n",
        "  APPG = \"APPG\" # 加速度脈波（二階微分）\n",
        "\n",
        "\n",
        "# シード値（パラメータではない）\n",
        "seed_1 = 42\n",
        "seed_2 = 810\n",
        "seed_3 = 114514"
      ],
      "metadata": {
        "id": "8jErFiq22y_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの水準を選択\n",
        "\n",
        "# 学習方法\n",
        "learning_type = Learning_Type.Fine_Tuning # ファインチューニング\n",
        "\n",
        "# 学習率\n",
        "#learning_rate = lr_1 # 5.00e-6\n",
        "learning_rate = lr_2 # 5.00e-5\n",
        "#learning_rate = lr_3 # 1.00e-4\n",
        "\n",
        "# バッチサイズ\n",
        "#batch_size = batch_size_1 # 16\n",
        "batch_size = batch_size_2 # 32\n",
        "#batch_size = batch_size_3 # 64\n",
        "\n",
        "# エポック数\n",
        "#num_epochs = num_epochs_1 # 15\n",
        "num_epochs = num_epochs_2 # 30\n",
        "#num_epochs = num_epochs_3 # 45\n",
        "\n",
        "# Stochastic Depth\n",
        "stochastic_depth = stochastic_depth_1 # 0.2\n",
        "#stochastic_depth = stochastic_depth_2 # 0.4\n",
        "#stochastic_depth = stochastic_depth_3 # 0.6\n",
        "\n",
        "# Weight Decay\n",
        "#weight_decay = weight_decay_1 # 1.00e-10\n",
        "weight_decay = weight_decay_2 # 1.00e-8\n",
        "#weight_decay = weight_decay_3 # 1.00e-6\n",
        "\n",
        "# サンプル画像\n",
        "sample_type = Sample_Type.PPG # ノーマル脈波\n",
        "#sample_type = Sample_Type.VPPG # 速度脈波\n",
        "#sample_type = Sample_Type.APPG # 加速度脈波\n",
        "\n",
        "# 乱数固定化\n",
        "#seed = seed_1 # 1回目\n",
        "#seed = seed_2 # 2回目\n",
        "seed = seed_3 # 3回目\n",
        "\n",
        "# 現在のハイパーパラメータ設定を表示\n",
        "print(f\"Now Learning_Type = {learning_type}\")\n",
        "print(f\"Now Learning_Rate = {learning_rate}\")\n",
        "print(f\"Now Batch_Size = {batch_size}\")\n",
        "print(f\"Now Num_Epochs = {num_epochs}\")\n",
        "print(f\"Now Stochastic_Depth = {stochastic_depth}\")\n",
        "print(f\"Now Weight_Decay = {weight_decay}\")\n",
        "print(f\"Now Sample_Type = {sample_type}\")\n",
        "\n",
        "# シード\n",
        "print(f\"Now Seed = {seed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLfOv-68hcml",
        "outputId": "1bc9d3eb-5098-4416-98d3-cef1c61229fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Learning_Type = ファインチューニング\n",
            "Now Learning_Rate = 5e-05\n",
            "Now Batch_Size = 32\n",
            "Now Num_Epochs = 30\n",
            "Now Stochastic_Depth = 0.2\n",
            "Now Weight_Decay = 1e-08\n",
            "Now Sample_Type = PPG\n",
            "Now Seed = 114514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 学習データをロード\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "# ファイルパス\n",
        "PPG_Path = \"/content/drive/MyDrive/反復写像図_バターワースフィルタ_sbp調整_180_ppg/反復写像図_standard=sbp140_len=22500_t=0.1\" # ノーマル脈波\n",
        "VPPG_Path = \"/content/drive/MyDrive/反復写像図_バターワースフィルタ_sbp調整_180_vppg/反復写像図_standard=sbp140_len=22500_t=0.1\" # VPPG\n",
        "APPG_Path = \"/content/drive/MyDrive/反復写像図_バターワースフィルタ_sbp調整_180_appg/反復写像図_standard=sbp140_len=22500_t=0.1\" # APPG\n",
        "\n",
        "\n",
        "\n",
        "# サンプル画像選択\n",
        "if(sample_type == Sample_Type.PPG):\n",
        "  full_file_path = PPG_Path\n",
        "elif(sample_type == Sample_Type.VPPG):\n",
        "  full_file_path = VPPG_Path\n",
        "elif(sample_type == Sample_Type.APPG):\n",
        "  full_file_path = APPG_Path\n",
        "else:\n",
        "  raise ValueError(\"sample_type が正しく設定されていません\")\n",
        "\n",
        "# 現在の画像タイプ表示\n",
        "print(f\"now file path:{full_file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# データセット取得\n",
        "# 学習用（データ拡張あり）\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root = full_file_path,\n",
        "    transform = train_transform\n",
        ")\n",
        "\n",
        "# 検証、テスト用（データ拡張なし）\n",
        "val_and_test_dataset = datasets.ImageFolder(\n",
        "    root = full_file_path,\n",
        "    transform = val_and_test_transform\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# ファイル順序が揃っているか確認\n",
        "paths1 = [s[0] for s in train_dataset.samples]\n",
        "paths2 = [s[0] for s in val_and_test_dataset.samples]\n",
        "print(f\"ファイル順序が同じか：{paths1 == paths2}\")\n",
        "\n",
        "# train_datasetのIDリスト取得\n",
        "targets = np.array(train_dataset.targets)\n",
        "\n",
        "# 再現性のためのシード\n",
        "print(f\"Now Seed = {seed}\")\n",
        "rng = np.random.RandomState(seed)\n",
        "\n",
        "# 元データのクラス分布（確認用）\n",
        "orig_counts = Counter(targets)\n",
        "print(\"Original class counts:\", orig_counts)\n",
        "\n",
        "\n",
        "# 分割比を決める（例：訓練70%, 検証15%, テスト15%）\n",
        "n_total = len(train_dataset)\n",
        "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n",
        "\n",
        "\n",
        "# まず train と 残り(temp=val+test) に層化分割(クラスの比率を保ったまま分割)\n",
        "idx = np.arange(n_total)\n",
        "train_idx, temp_idx = train_test_split(\n",
        "    idx,\n",
        "    test_size=(1.0 - train_ratio),\n",
        "    stratify=targets,\n",
        "    random_state=seed,\n",
        ")\n",
        "\n",
        "# 残り(temp)を val と test に層化分割(クラスの比率を保ったまま分轄)\n",
        "temp_targets = targets[temp_idx]\n",
        "test_size_in_temp = test_ratio / (val_ratio + test_ratio)\n",
        "val_idx, test_idx = train_test_split(\n",
        "    temp_idx,\n",
        "    test_size=test_size_in_temp,\n",
        "    stratify=temp_targets,\n",
        "    random_state=seed,\n",
        ")\n",
        "\n",
        "# 学習、検証、テストデータセット作成\n",
        "# 各IDリストに対応するファイルを、それぞれのDatasetからインポート\n",
        "train_ds = Subset(train_dataset, train_idx)\n",
        "val_ds   = Subset(val_and_test_dataset,  val_idx)\n",
        "test_ds  = Subset(val_and_test_dataset,  test_idx)\n",
        "\n",
        "# 各データセットのクラス分布を確認\n",
        "def count_by_class(subset):\n",
        "    labels = [train_dataset.samples[i][1] for i in subset.indices]\n",
        "    return Counter(labels)\n",
        "\n",
        "print(train_dataset.class_to_idx)\n",
        "print(val_and_test_dataset.class_to_idx)\n",
        "print(\"Train size:\", len(train_ds), \"class counts:\", count_by_class(train_ds))\n",
        "print(\"Val   size:\", len(val_ds),   \"class counts:\", count_by_class(val_ds))\n",
        "print(\"Test  size:\", len(test_ds),  \"class counts:\", count_by_class(test_ds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV5-F--VgRKk",
        "outputId": "35761d62-db1d-4f38-bcdb-2026363220a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now file path:/content/drive/MyDrive/反復写像図_バターワースフィルタ_sbp調整_180_ppg/反復写像図_standard=sbp140_len=22500_t=0.1\n",
            "ファイル順序が同じか：True\n",
            "Now Seed = 114514\n",
            "Original class counts: Counter({np.int64(1): 6975, np.int64(0): 3303})\n",
            "{'above_sbp140': 0, 'below_sbp140': 1}\n",
            "{'above_sbp140': 0, 'below_sbp140': 1}\n",
            "Train size: 7194 class counts: Counter({1: 4882, 0: 2312})\n",
            "Val   size: 1542 class counts: Counter({1: 1046, 0: 496})\n",
            "Test  size: 1542 class counts: Counter({1: 1047, 0: 495})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.class_to_idx)\n",
        "print(val_and_test_dataset.class_to_idx)"
      ],
      "metadata": {
        "id": "52LXwTRnUsyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットの画像を例示（確認用）\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 分類先クラスのリスト作成\n",
        "classes = ['above_sbp', 'below_sbp']\n",
        "\n",
        "plt.figure(figsize=(15, 4))\n",
        "for i in range(8):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "    image, label = test_ds[i]\n",
        "    img = (np.transpose(image.numpy(), (1, 2, 0)) + 1)/2\n",
        "    plt.imshow(img)\n",
        "    ax.set_title(classes[label])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, 10, i + 11)\n",
        "    image, label = test_ds[-i-1]\n",
        "    img = (np.transpose(image.numpy(), (1, 2, 0)) + 1)/2\n",
        "    plt.imshow(img)\n",
        "    ax.set_title(classes[label])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z9dmQrrAmEwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### サンプラー作成\n",
        "### 訓練用データセットにおいて、クラス分布を均等にする\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "# ラベル情報取得\n",
        "data_list_targets = np.array(train_ds.dataset.targets)\n",
        "\n",
        "train_targets = np.array(data_list_targets[train_idx])\n",
        "\n",
        "print(train_targets.shape)\n",
        "\n",
        "# 各ラベルの頻度\n",
        "class_counts = np.bincount(train_targets)   # [2000, 8000]\n",
        "\n",
        "# サンプルごとの重み = 1 / クラスの頻度\n",
        "sample_weights = 1.0 / class_counts[train_targets]\n",
        "sample_weights = torch.tensor(sample_weights, dtype=torch.double)\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qceBYUeRot2x",
        "outputId": "4bf1bffd-33c8-41ea-d90d-8ee220dd0947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7194,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### DataLoaderの作成\n",
        "import os\n",
        "\n",
        "# データ読み込みを並列化するプロセス数\n",
        "num_workers = os.cpu_count() - 1\n",
        "pin_memory   = True    # CUDA使用時に高速化（GPUに直接転送）\n",
        "\n",
        "# バッチサイズ確認\n",
        "print(f\"Now Batch Size = {batch_size}\")\n",
        "\n",
        "\n",
        "# DataLoader の作成\n",
        "train_loader = DataLoader(\n",
        "    train_ds,      # Subset or ImageFolder\n",
        "    batch_size=batch_size,\n",
        "    #shuffle=True,       # サンプラーを使うので、シャッフルはなし\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,      # 検証では順序固定\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,      # テストでは順序固定\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory\n",
        ")\n",
        "\n",
        "# 3) 動作確認\n",
        "for images, labels in train_loader:\n",
        "    print(\"  images:\", images.shape)   # 例: [batch_size, 3, 224, 224]\n",
        "    print(\"  labels:\", labels)         # 例: tensor([0,1,0,1, …])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ky6FTLumNCL",
        "outputId": "e6c49dde-1904-417d-eac7-f6162da3ff5c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Batch Size = 32\n",
            "  images: torch.Size([32, 3, 224, 224])\n",
            "  labels: tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "        1, 0, 1, 0, 0, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 現在のランタイムタイプ確認\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GHjOC-cmtD_",
        "outputId": "aebfdb2a-49ef-4c08-e1ac-d8aa93a117ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 事前学習済みモデルインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import random\n",
        "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
        "\n",
        "\n",
        "# デバイス\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# シード\n",
        "print(f\"Now Seed = {seed}\")\n",
        "\n",
        "random.seed(seed)                    # Python 標準 random\n",
        "np.random.seed(seed)                 # NumPy\n",
        "torch.manual_seed(seed)              # PyTorch CPU\n",
        "torch.cuda.manual_seed(seed)         # PyTorch GPU (CUDA)\n",
        "torch.cuda.manual_seed_all(seed)     # 全GPUに適用\n",
        "torch.backends.cudnn.benchmark = False # 畳み込み演算での再現性無視\n",
        "torch.backends.cudnn.deterministic = True # 決定的なpytorchの操作\n",
        "\n",
        "#stochastic_depth確認\n",
        "print(f\"Now Stochastic Depth = {stochastic_depth}\")\n",
        "\n",
        "# モデル\n",
        "# 事前学習済み ConveNeXt_Base\n",
        "# ダウンロード\n",
        "model = convnext_base(weights= ConvNeXt_Base_Weights, stochastic_depth_prob= stochastic_depth)\n",
        "\n",
        "# 事前学習をしていないモデルを使いたい場合は以下のコードを実行\n",
        "# model = convnext_base(stochastic_depth_prob= stochastic_depth)"
      ],
      "metadata": {
        "id": "K0SVcvicm6UA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe431dd-ffa8-4c0e-afbe-aef4a1db4ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Seed = 114514\n",
            "Now Stochastic Depth = 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ConveNeXt_Baseのサマリー\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PL50e4N2p5_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88867e74-fe93-4ecd-c63c-cf5b9f5a7572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "ConvNeXt                                      [1, 1000]                 --\n",
              "├─Sequential: 1-1                             [1, 1024, 7, 7]           --\n",
              "│    └─Conv2dNormActivation: 2-1              [1, 128, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-1                       [1, 128, 56, 56]          6,272\n",
              "│    │    └─LayerNorm2d: 3-2                  [1, 128, 56, 56]          256\n",
              "│    └─Sequential: 2-2                        [1, 128, 56, 56]          --\n",
              "│    │    └─CNBlock: 3-3                      [1, 128, 56, 56]          138,496\n",
              "│    │    └─CNBlock: 3-4                      [1, 128, 56, 56]          138,496\n",
              "│    │    └─CNBlock: 3-5                      [1, 128, 56, 56]          138,496\n",
              "│    └─Sequential: 2-3                        [1, 256, 28, 28]          --\n",
              "│    │    └─LayerNorm2d: 3-6                  [1, 128, 56, 56]          256\n",
              "│    │    └─Conv2d: 3-7                       [1, 256, 28, 28]          131,328\n",
              "│    └─Sequential: 2-4                        [1, 256, 28, 28]          --\n",
              "│    │    └─CNBlock: 3-8                      [1, 256, 28, 28]          539,136\n",
              "│    │    └─CNBlock: 3-9                      [1, 256, 28, 28]          539,136\n",
              "│    │    └─CNBlock: 3-10                     [1, 256, 28, 28]          539,136\n",
              "│    └─Sequential: 2-5                        [1, 512, 14, 14]          --\n",
              "│    │    └─LayerNorm2d: 3-11                 [1, 256, 28, 28]          512\n",
              "│    │    └─Conv2d: 3-12                      [1, 512, 14, 14]          524,800\n",
              "│    └─Sequential: 2-6                        [1, 512, 14, 14]          --\n",
              "│    │    └─CNBlock: 3-13                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-14                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-15                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-16                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-17                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-18                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-19                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-20                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-21                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-22                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-23                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-24                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-25                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-26                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-27                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-28                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-29                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-30                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-31                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-32                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-33                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-34                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-35                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-36                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-37                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-38                     [1, 512, 14, 14]          2,126,848\n",
              "│    │    └─CNBlock: 3-39                     [1, 512, 14, 14]          2,126,848\n",
              "│    └─Sequential: 2-7                        [1, 1024, 7, 7]           --\n",
              "│    │    └─LayerNorm2d: 3-40                 [1, 512, 14, 14]          1,024\n",
              "│    │    └─Conv2d: 3-41                      [1, 1024, 7, 7]           2,098,176\n",
              "│    └─Sequential: 2-8                        [1, 1024, 7, 7]           --\n",
              "│    │    └─CNBlock: 3-42                     [1, 1024, 7, 7]           8,448,000\n",
              "│    │    └─CNBlock: 3-43                     [1, 1024, 7, 7]           8,448,000\n",
              "│    │    └─CNBlock: 3-44                     [1, 1024, 7, 7]           8,448,000\n",
              "├─AdaptiveAvgPool2d: 1-2                      [1, 1024, 1, 1]           --\n",
              "├─Sequential: 1-3                             [1, 1000]                 --\n",
              "│    └─LayerNorm2d: 2-9                       [1, 1024, 1, 1]           2,048\n",
              "│    └─Flatten: 2-10                          [1, 1024]                 --\n",
              "│    └─Linear: 2-11                           [1, 1000]                 1,025,000\n",
              "===============================================================================================\n",
              "Total params: 88,591,464\n",
              "Trainable params: 88,591,464\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 646.53\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 276.18\n",
              "Params size (MB): 354.29\n",
              "Estimated Total Size (MB): 631.08\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ConveNeXt_Baseのモデル構造\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QCPz176uqCeQ",
        "outputId": "1e6d05a3-b41e-48a1-e032-df823ba27ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNeXt(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "      )\n",
            "      (1): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.005714285714285714, mode=row)\n",
            "      )\n",
            "      (2): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.011428571428571429, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
            "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.017142857142857144, mode=row)\n",
            "      )\n",
            "      (1): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.022857142857142857, mode=row)\n",
            "      )\n",
            "      (2): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.02857142857142857, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
            "      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.03428571428571429, mode=row)\n",
            "      )\n",
            "      (1): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
            "      )\n",
            "      (2): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.045714285714285714, mode=row)\n",
            "      )\n",
            "      (3): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05142857142857143, mode=row)\n",
            "      )\n",
            "      (4): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05714285714285714, mode=row)\n",
            "      )\n",
            "      (5): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.06285714285714286, mode=row)\n",
            "      )\n",
            "      (6): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.06857142857142857, mode=row)\n",
            "      )\n",
            "      (7): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.07428571428571429, mode=row)\n",
            "      )\n",
            "      (8): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
            "      )\n",
            "      (9): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08571428571428572, mode=row)\n",
            "      )\n",
            "      (10): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.09142857142857143, mode=row)\n",
            "      )\n",
            "      (11): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.09714285714285716, mode=row)\n",
            "      )\n",
            "      (12): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.10285714285714286, mode=row)\n",
            "      )\n",
            "      (13): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.10857142857142858, mode=row)\n",
            "      )\n",
            "      (14): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.11428571428571428, mode=row)\n",
            "      )\n",
            "      (15): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
            "      )\n",
            "      (16): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.12571428571428572, mode=row)\n",
            "      )\n",
            "      (17): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.13142857142857145, mode=row)\n",
            "      )\n",
            "      (18): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.13714285714285715, mode=row)\n",
            "      )\n",
            "      (19): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.14285714285714285, mode=row)\n",
            "      )\n",
            "      (20): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.14857142857142858, mode=row)\n",
            "      )\n",
            "      (21): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1542857142857143, mode=row)\n",
            "      )\n",
            "      (22): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
            "      )\n",
            "      (23): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.16571428571428573, mode=row)\n",
            "      )\n",
            "      (24): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17142857142857143, mode=row)\n",
            "      )\n",
            "      (25): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17714285714285716, mode=row)\n",
            "      )\n",
            "      (26): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.18285714285714286, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.18857142857142858, mode=row)\n",
            "      )\n",
            "      (1): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1942857142857143, mode=row)\n",
            "      )\n",
            "      (2): CNBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
            "          (1): Permute()\n",
            "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (4): GELU(approximate='none')\n",
            "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (6): Permute()\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=1024, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### モデル調整\n",
        "\n",
        "if learning_type == Learning_Type.Transfer_Learning:\n",
        "  # 転移学習の場合、すべてのパラメータで勾配計算なしに(効果なかったので使用せず)\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "elif learning_type == Learning_Type.Fine_Tuning:\n",
        "  # ファインチューニングの場合（基本こっち）\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = True\n",
        "else:\n",
        "  raise ValueError(\"learning_type が正しく設定されていません\")\n",
        "\n",
        "\n",
        "\n",
        "# 最終層付け替え 出力を2次元に\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, len(train_ds.dataset.classes))\n",
        "\n",
        "# 確認\n",
        "for param in model.parameters():\n",
        "   # print(param)\n",
        "    print(param.requires_grad)\n",
        "\n",
        "# 現在の学習方法表示\n",
        "print(f\"now learning type:{learning_type}\")\n",
        "\n",
        "\n",
        "# モデルの最終層\n",
        "print(f'モデル最終層={model.classifier[-1]}')\n",
        "\n",
        "# モデルの最終層入力サイズ\n",
        "print(f'モデル最終層入力サイズ={model.classifier[-1].in_features}')\n",
        "\n",
        "# 転送\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6n_A23B7qf-l",
        "outputId": "8e8a24c4-f799-4afc-dc2e-48860fd5d1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "now learning type:ファインチューニング\n",
            "モデル最終層=Linear(in_features=1024, out_features=2, bias=True)\n",
            "モデル最終層入力サイズ=1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 損失関数、最適化関数設定\n",
        "\n",
        "# 使わなかった部分\n",
        "#--------------------------------------------------------------------------\n",
        "# クラスの重み付け\n",
        "#フルデータセットからクラスごとの数を取得\n",
        "# クラスの出現数\n",
        "#class_counts = torch.tensor([3303, 6975], dtype=torch.float32)\n",
        "# 出現数の逆数を重みとして使う（少ないクラスを重視）\n",
        "#class_weights = 1.0 / class_counts\n",
        "#class_weights = class_weights / class_weights.sum()  # 正規化\n",
        "\n",
        "# GPUに送る\n",
        "#class_weights = class_weights.to(device)\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
        "\n",
        "#-------------------------------------------------------------------------- ここまで\n",
        "\n",
        "\n",
        "# 損失関数　クロスエントロピー(ラベルスムージングあり)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "\n",
        "# 学習率確認\n",
        "print(f\"Now Learing Rate = {learning_rate}\")\n",
        "\n",
        "# Weight_Decay確認\n",
        "print(f\"Now Weight Decay = {weight_decay}\")\n",
        "\n",
        "# 最適化関数設定\n",
        "# AdamWを使用\n",
        "if learning_type == Learning_Type.Transfer_Learning:\n",
        "  # 転移学習の場合（効果なかったので使用せず）\n",
        "  optimizer = optim.AdamW(\n",
        "    model.classifier[-1].parameters(), # パラメータ更新は最終層のみ\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "elif learning_type == Learning_Type.Fine_Tuning:\n",
        "  # ファインチューニングの場合（基本こっち）\n",
        "  optimizer = optim.AdamW(\n",
        "    model.parameters(), # 全パラメータ更新\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "else:\n",
        "  raise ValueError(\"learning_type が正しく設定されていません\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PWxXRx4Pr4u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a83c8af-aa83-43e6-a2d5-f69647ac4e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Learing Rate = 5e-05\n",
            "Now Weight Decay = 1e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### エポック数表示\n",
        "print(f\"Now Epochs = {num_epochs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xftxblu6Zmfe",
        "outputId": "46c04f1a-b45e-4e99-94c8-21f0981b924c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Epochs = 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 学習開始\n",
        "!pip install -q tqdm\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import torch\n",
        "from torch import amp\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "import math\n",
        "\n",
        "\n",
        "POS_CLASS = 0  # \"above\" がクラスインデックス 0\n",
        "\n",
        "# best の管理（val_f1 でモデルを選ぶようにする）\n",
        "best_val_f1 = -1.0\n",
        "best_state = None\n",
        "best_threshold_saved = 0.5  # ベストモデル時の閾値を保存\n",
        "\n",
        "# ------------------------------------------------------\n",
        "eps = 1e-12\n",
        "# 一度だけ計算しておく (学習ループの前)\n",
        "# 各ラベルの頻度\n",
        "val_data_list_targets = np.array(val_ds.dataset.targets)\n",
        "val_targets = np.array(val_data_list_targets[val_idx])\n",
        "val_total_samples = len(val_targets)\n",
        "val_labels_total_positive = np.bincount(val_targets)[0]\n",
        "print(f\"val_total_samples:{val_total_samples}\")\n",
        "print(f\"val_labels_total_positive:{val_labels_total_positive}\")\n",
        "\n",
        "\n",
        "P_train_pos = 0.5 # 訓練時事前確率 サンプラーのせい\n",
        "P_val_pos   = float((val_labels_total_positive) / (val_total_samples))  # または本番想定比\n",
        "\n",
        "\n",
        "print(f\"P_train_pos:{P_train_pos}\")\n",
        "print(f\"P_val_pos:{P_val_pos}\")\n",
        "\n",
        "# 検証ループ外で delta を一回計算\n",
        "delta = math.log( max(eps, P_val_pos) / max(eps, (1.0-P_val_pos)) ) \\\n",
        "      - math.log( max(eps, P_train_pos) / max(eps, (1.0-P_train_pos)) )\n",
        "\n",
        "print(f\"delta:{delta}\")\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# 混同行列表示関数\n",
        "def print_confusion_counts_and_percents(y_true, y_pred, label_names):\n",
        "\n",
        "    # numpyに変換\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # 混同行列計算　ラベル0が陽性、1が陰性\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tp, fn, fp, tn = cm.flatten()  # TP、FN、FP、TN\n",
        "    total = tp + fn + fp + tn\n",
        "    if total == 0:\n",
        "        total = 1  # avoid zero division, though usually shouldn't happen\n",
        "\n",
        "    def pct(x): return (x / total) * 100.0\n",
        "\n",
        "    # Print\n",
        "    print(\"Confusion matrix (rows=true, cols=pred) with label order:\", label_names)\n",
        "    print(cm)\n",
        "    print(f\"TP: {tp} ({pct(tp):.2f}%)\")\n",
        "    print(f\"FN: {fn} ({pct(fn):.2f}%)\")\n",
        "    print(f\"FP: {fp} ({pct(fp):.2f}%)\")\n",
        "    print(f\"TN: {tn} ({pct(tn):.2f}%)\")\n",
        "    return {\"cm\": cm, \"tp\": tp,\"fn\": fn,\"fp\": fp,\"tn\": tn, \"total\": total}\n",
        "\n",
        "\n",
        "scaler = amp.GradScaler('cuda')  # 勾配スケーラーを作成\n",
        "                       # 計算速度向上のため、16bit浮動小数点で計算\n",
        "                       # 制度が必要な部分のみ32bit浮動小数点で計算\n",
        "\n",
        "best_val_acc = 0.0 # 正解率の最高値\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[{epoch+1}/{num_epochs}] Training...\")\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    running_total = 0\n",
        "\n",
        "    # 正解と予測を保存するリスト\n",
        "    y_true_train = []\n",
        "    y_pred_train = []\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} train\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          #loss.backward()\n",
        "          #optimizer.step()\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()     # ← 勾配をスケーリングしてbackward\n",
        "        scaler.step(optimizer)            # ← スケーリングしたままoptimizer\n",
        "        scaler.update()                   # ← スケール因子を自動調整\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        running_loss += loss.item() * batch_size\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        running_corrects += (preds == labels).sum().item()\n",
        "        running_total += batch_size\n",
        "\n",
        "        y_true_train.extend(labels.cpu().numpy())\n",
        "        y_pred_train.extend(preds.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / running_total\n",
        "    epoch_acc  = running_corrects / running_total\n",
        "\n",
        "    # train F1（陽性クラスを POS_CLASS として計算）\n",
        "    # y_true_train, y_pred_train は 0/1 のラベルなので pos_label に POS_CLASS を渡す\n",
        "    try:\n",
        "        train_f1_epoch = f1_score(np.array(y_true_train), np.array(y_pred_train), pos_label=POS_CLASS)\n",
        "    except Exception as e:\n",
        "        # 万一計算できない（例: 該当クラスのサンプルがない等）は NaN として扱う\n",
        "        print(\"Warning: train F1 could not be computed:\", e)\n",
        "        train_f1_epoch = float(\"nan\")\n",
        "\n",
        "    print(f\"train loss: {epoch_loss:.4f}, train acc: {epoch_acc:.2%}, train F1(pos={POS_CLASS}): {train_f1_epoch:.4f}\")\n",
        "\n",
        "    #print(f\"train loss: {epoch_loss:.4f}, train acc: {epoch_acc:.2%}\")\n",
        "\n",
        "    print(\"Train confusion (epoch):\")\n",
        "    print_confusion_counts_and_percents(y_true_train, y_pred_train, label_names=[\"above\",\"below\"])\n",
        "\n",
        "\n",
        "\n",
        "    # === validation ===\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    # val_correct, val_total = 0, 0   # <- val_correct は閾値適用後に計算するのでここでは使わない\n",
        "    val_total = 0\n",
        "    y_true_val = []\n",
        "    # --- collect probs and labels ---\n",
        "    val_probs_list = []\n",
        "    val_labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            batch_size = images.size(0)\n",
        "            val_running_loss += loss.item() * batch_size\n",
        "            val_total += batch_size\n",
        "\n",
        "            # ---------------- 検証ループ内（outputs は logits） ----------------\n",
        "            # そのまま softmax を使う代わりに positive の logit にオフセットを加える\n",
        "            logits_adj = outputs.clone()\n",
        "            logits_adj[:, POS_CLASS] = logits_adj[:, POS_CLASS] + delta   # 事前確率補正\n",
        "            probs = torch.softmax(logits_adj, dim=1)[:, POS_CLASS].detach().cpu().numpy()\n",
        "            # ----------------------------------------------------------------\n",
        "\n",
        "            # save logits/probs and labels for threshold tuning\n",
        "            #probs = torch.softmax(outputs, dim=1)[:, POS_CLASS].detach().cpu().numpy()  # positive class prob\n",
        "            val_probs_list.append(probs)\n",
        "            val_labels_list.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    # concat\n",
        "    val_probs = np.concatenate(val_probs_list)   # shape (N,)\n",
        "    val_labels = np.concatenate(val_labels_list) # shape (N,)\n",
        "\n",
        "    # 1) find best threshold by maximizing F1 on validation (precision-recall curve)\n",
        "    prec, rec, thresholds = precision_recall_curve((val_labels == POS_CLASS).astype(int), val_probs, pos_label=1)\n",
        "    if len(thresholds) == 0:\n",
        "        best_threshold = 0.5\n",
        "        best_val_f1_epoch = f1_score((val_labels == POS_CLASS).astype(int), (val_probs >= best_threshold).astype(int))\n",
        "    else:\n",
        "        f1_scores = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12)\n",
        "        best_idx = np.nanargmax(f1_scores)\n",
        "        best_threshold = thresholds[best_idx]\n",
        "        best_val_f1_epoch = float(f1_scores[best_idx])\n",
        "\n",
        "    # 閾値表示\n",
        "    print(f\"Validation best threshold (epoch {epoch+1}): {best_threshold:.4f}\")\n",
        "\n",
        "    # 2) apply best_threshold to get preds and metrics\n",
        "    val_preds_binary = (val_probs >= best_threshold).astype(int)  # 1 == POS_CLASS predicted\n",
        "    # convert binary back to label indices (0 or 1)\n",
        "    val_preds = np.where(val_preds_binary == 1, POS_CLASS, 1 - POS_CLASS)\n",
        "\n",
        "    val_correct = (val_preds == val_labels).sum()\n",
        "    val_acc = val_correct / val_total\n",
        "    val_loss = val_running_loss / val_total\n",
        "\n",
        "    print(f\"val loss: {val_loss:.4f}, val acc: {val_acc:.2%}, val F1(pos={POS_CLASS}): {best_val_f1_epoch:.4f}\")\n",
        "    print(\"Validation confusion (epoch):\")\n",
        "    print_confusion_counts_and_percents(val_labels, val_preds, label_names=[\"above\",\"below\"])\n",
        "\n",
        "    # 3) モデル保存基準を val_f1 に変更（閾値も保存）\n",
        "    if best_val_f1_epoch > best_val_f1:\n",
        "        best_val_f1 = best_val_f1_epoch\n",
        "        best_state = copy.deepcopy(model.state_dict())\n",
        "        best_threshold_saved = best_threshold\n",
        "        print(f\"New best val_F1: {best_val_f1:.4f} (model saved, threshold={best_threshold:.4f})\")\n",
        "    # ---------------- end validation block ----------------\n",
        "\n",
        "# ---------------- test 部分（学習終了後の test） ----------------\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)  # valで最良の重みをロード\n",
        "    use_threshold = best_threshold_saved\n",
        "else:\n",
        "    use_threshold = 0.5\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# test で確率も集めて F1 を計算できるようにする\n",
        "test_probs_list = []\n",
        "test_labels_list = []\n",
        "\n",
        "model.eval()\n",
        "test_running_loss = 0.0\n",
        "test_correct, test_total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Test\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        test_running_loss += loss.item() * batch_size\n",
        "        test_total += batch_size\n",
        "\n",
        "        # 修正版（validation と同じく delta を適用してから softmax）\n",
        "        logits_adj = outputs.clone()\n",
        "        logits_adj[:, POS_CLASS] = logits_adj[:, POS_CLASS] + delta\n",
        "        probs = torch.softmax(logits_adj, dim=1)[:, POS_CLASS].cpu().numpy()\n",
        "\n",
        "        test_probs_list.append(probs)\n",
        "        test_labels_list.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        #probs = torch.softmax(outputs, dim=1)[:, POS_CLASS].cpu().numpy()\n",
        "        preds_binary = (probs >= use_threshold).astype(int)\n",
        "        preds = np.where(preds_binary == 1, POS_CLASS, 1 - POS_CLASS)\n",
        "\n",
        "        test_correct += (preds == labels.detach().cpu().numpy()).sum().item()\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "test_loss = test_running_loss / test_total\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"Test loss: {test_loss:.4f}, Test acc%: {test_acc:.2%}, Test acc: {test_acc:.4f}\")\n",
        "\n",
        "# concat test probs/labels として test F1 を算出（use_threshold を使って評価）\n",
        "test_probs = np.concatenate(test_probs_list)\n",
        "test_labels = np.concatenate(test_labels_list)\n",
        "test_y_true_bin = (test_labels == POS_CLASS).astype(int)\n",
        "test_preds_bin_by_used = (test_probs >= use_threshold).astype(int)\n",
        "test_f1_by_used = f1_score(test_y_true_bin, test_preds_bin_by_used)\n",
        "\n",
        "print(f\"Test F1 (pos={POS_CLASS}) using threshold {use_threshold:.4f} F1: {test_f1_by_used:.4f}\")\n",
        "\n",
        "\n",
        "# 混同行列を作成\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"above\", \"below\"])\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.show()\n",
        "# ---------------- end test block ----------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aLRQKw5LxYDO",
        "outputId": "51f1b073-722b-4e0c-d451-c37df6a6fd40",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_total_samples:1542\n",
            "val_labels_total_positive:496\n",
            "P_train_pos:0.5\n",
            "P_val_pos:0.3216601815823606\n",
            "delta:-0.7461527178999408\n",
            "[1/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 1 train: 100%|██████████| 225/225 [01:37<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.7290, train acc: 50.01%, train F1(pos=0): 0.5361\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2078 1623]\n",
            " [1973 1520]]\n",
            "TP: 2078 (28.89%)\n",
            "FN: 1623 (22.56%)\n",
            "FP: 1973 (27.43%)\n",
            "TN: 1520 (21.13%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:36<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 1): 0.3257\n",
            "val loss: 0.6991, val acc: 32.94%, val F1(pos=0): 0.4881\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 493    3]\n",
            " [1031   15]]\n",
            "TP: 493 (31.97%)\n",
            "FN: 3 (0.19%)\n",
            "FP: 1031 (66.86%)\n",
            "TN: 15 (0.97%)\n",
            "New best val_F1: 0.4881 (model saved, threshold=0.3257)\n",
            "[2/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 2 train: 100%|██████████| 225/225 [00:53<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.7010, train acc: 49.93%, train F1(pos=0): 0.4822\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1677 1849]\n",
            " [1753 1915]]\n",
            "TP: 1677 (23.31%)\n",
            "FN: 1849 (25.70%)\n",
            "FP: 1753 (24.37%)\n",
            "TN: 1915 (26.62%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 2): 0.3181\n",
            "val loss: 0.6919, val acc: 32.56%, val F1(pos=0): 0.4877\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 495    1]\n",
            " [1039    7]]\n",
            "TP: 495 (32.10%)\n",
            "FN: 1 (0.06%)\n",
            "FP: 1039 (67.38%)\n",
            "TN: 7 (0.45%)\n",
            "[3/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 3 train: 100%|██████████| 225/225 [00:49<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6945, train acc: 50.93%, train F1(pos=0): 0.5451\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2115 1508]\n",
            " [2022 1549]]\n",
            "TP: 2115 (29.40%)\n",
            "FN: 1508 (20.96%)\n",
            "FP: 2022 (28.11%)\n",
            "TN: 1549 (21.53%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 3): 0.3135\n",
            "val loss: 0.6881, val acc: 32.62%, val F1(pos=0): 0.4874\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 494    2]\n",
            " [1037    9]]\n",
            "TP: 494 (32.04%)\n",
            "FN: 2 (0.13%)\n",
            "FP: 1037 (67.25%)\n",
            "TN: 9 (0.58%)\n",
            "[4/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 4 train: 100%|██████████| 225/225 [00:48<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6957, train acc: 50.49%, train F1(pos=0): 0.5295\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2004 1636]\n",
            " [1926 1628]]\n",
            "TP: 2004 (27.86%)\n",
            "FN: 1636 (22.74%)\n",
            "FP: 1926 (26.77%)\n",
            "TN: 1628 (22.63%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 4): 0.3372\n",
            "val loss: 0.7056, val acc: 32.43%, val F1(pos=0): 0.4877\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1042    4]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1042 (67.57%)\n",
            "TN: 4 (0.26%)\n",
            "[5/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 5 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6941, train acc: 49.92%, train F1(pos=0): 0.5013\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1811 1776]\n",
            " [1827 1780]]\n",
            "TP: 1811 (25.17%)\n",
            "FN: 1776 (24.69%)\n",
            "FP: 1827 (25.40%)\n",
            "TN: 1780 (24.74%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 5): 0.3340\n",
            "val loss: 0.7030, val acc: 32.30%, val F1(pos=0): 0.4872\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1044    2]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1044 (67.70%)\n",
            "TN: 2 (0.13%)\n",
            "[6/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 6 train: 100%|██████████| 225/225 [00:48<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6936, train acc: 49.76%, train F1(pos=0): 0.5424\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2142 1511]\n",
            " [2103 1438]]\n",
            "TP: 2142 (29.77%)\n",
            "FN: 1511 (21.00%)\n",
            "FP: 2103 (29.23%)\n",
            "TN: 1438 (19.99%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 6): 0.3184\n",
            "val loss: 0.6911, val acc: 32.30%, val F1(pos=0): 0.4872\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1044    2]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1044 (67.70%)\n",
            "TN: 2 (0.13%)\n",
            "[7/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 7 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 7 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6939, train acc: 50.46%, train F1(pos=0): 0.6274\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[3001  685]\n",
            " [2879  629]]\n",
            "TP: 3001 (41.72%)\n",
            "FN: 685 (9.52%)\n",
            "FP: 2879 (40.02%)\n",
            "TN: 629 (8.74%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 7): 0.3098\n",
            "val loss: 0.6851, val acc: 32.30%, val F1(pos=0): 0.4872\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1044    2]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1044 (67.70%)\n",
            "TN: 2 (0.13%)\n",
            "[8/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 8 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6943, train acc: 49.94%, train F1(pos=0): 0.4461\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1450 2117]\n",
            " [1484 2143]]\n",
            "TP: 1450 (20.16%)\n",
            "FN: 2117 (29.43%)\n",
            "FP: 1484 (20.63%)\n",
            "TN: 2143 (29.79%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 8): 0.2903\n",
            "val loss: 0.6723, val acc: 32.56%, val F1(pos=0): 0.4877\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 495    1]\n",
            " [1039    7]]\n",
            "TP: 495 (32.10%)\n",
            "FN: 1 (0.06%)\n",
            "FP: 1039 (67.38%)\n",
            "TN: 7 (0.45%)\n",
            "[9/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 9 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6942, train acc: 50.04%, train F1(pos=0): 0.5265\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1998 1619]\n",
            " [1975 1602]]\n",
            "TP: 1998 (27.77%)\n",
            "FN: 1619 (22.50%)\n",
            "FP: 1975 (27.45%)\n",
            "TN: 1602 (22.27%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 9): 0.2861\n",
            "val loss: 0.6699, val acc: 32.17%, val F1(pos=0): 0.4868\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1046    0]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1046 (67.83%)\n",
            "TN: 0 (0.00%)\n",
            "[10/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 10 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 10 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6939, train acc: 50.64%, train F1(pos=0): 0.4015\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1191 2341]\n",
            " [1210 2452]]\n",
            "TP: 1191 (16.56%)\n",
            "FN: 2341 (32.54%)\n",
            "FP: 1210 (16.82%)\n",
            "TN: 2452 (34.08%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 10): 0.2986\n",
            "val loss: 0.6776, val acc: 32.23%, val F1(pos=0): 0.4870\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1045    1]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1045 (67.77%)\n",
            "TN: 1 (0.06%)\n",
            "[11/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 11 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 11 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6939, train acc: 49.62%, train F1(pos=0): 0.5659\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2362 1286]\n",
            " [2338 1208]]\n",
            "TP: 2362 (32.83%)\n",
            "FN: 1286 (17.88%)\n",
            "FP: 2338 (32.50%)\n",
            "TN: 1208 (16.79%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 11): 0.3262\n",
            "val loss: 0.6968, val acc: 32.81%, val F1(pos=0): 0.4881\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 494    2]\n",
            " [1034   12]]\n",
            "TP: 494 (32.04%)\n",
            "FN: 2 (0.13%)\n",
            "FP: 1034 (67.06%)\n",
            "TN: 12 (0.78%)\n",
            "New best val_F1: 0.4881 (model saved, threshold=0.3262)\n",
            "[12/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 12 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 12 train: 100%|██████████| 225/225 [00:48<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6945, train acc: 49.25%, train F1(pos=0): 0.4346\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1403 2137]\n",
            " [1514 2140]]\n",
            "TP: 1403 (19.50%)\n",
            "FN: 2137 (29.71%)\n",
            "FP: 1514 (21.05%)\n",
            "TN: 2140 (29.75%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 12): 0.3176\n",
            "val loss: 0.6905, val acc: 34.31%, val F1(pos=0): 0.4892\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 485   11]\n",
            " [1002   44]]\n",
            "TP: 485 (31.45%)\n",
            "FN: 11 (0.71%)\n",
            "FP: 1002 (64.98%)\n",
            "TN: 44 (2.85%)\n",
            "New best val_F1: 0.4892 (model saved, threshold=0.3176)\n",
            "[13/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 13 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 13 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6945, train acc: 49.58%, train F1(pos=0): 0.4791\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1668 1912]\n",
            " [1715 1899]]\n",
            "TP: 1668 (23.19%)\n",
            "FN: 1912 (26.58%)\n",
            "FP: 1715 (23.84%)\n",
            "TN: 1899 (26.40%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 13): 0.3335\n",
            "val loss: 0.7021, val acc: 47.80%, val F1(pos=0): 0.4972\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[398  98]\n",
            " [707 339]]\n",
            "TP: 398 (25.81%)\n",
            "FN: 98 (6.36%)\n",
            "FP: 707 (45.85%)\n",
            "TN: 339 (21.98%)\n",
            "New best val_F1: 0.4972 (model saved, threshold=0.3335)\n",
            "[14/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 14 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 14 train: 100%|██████████| 225/225 [00:48<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6936, train acc: 50.31%, train F1(pos=0): 0.5537\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2218 1421]\n",
            " [2154 1401]]\n",
            "TP: 2218 (30.83%)\n",
            "FN: 1421 (19.75%)\n",
            "FP: 2154 (29.94%)\n",
            "TN: 1401 (19.47%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 14): 0.3176\n",
            "val loss: 0.6904, val acc: 45.01%, val F1(pos=0): 0.5058\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[434  62]\n",
            " [786 260]]\n",
            "TP: 434 (28.15%)\n",
            "FN: 62 (4.02%)\n",
            "FP: 786 (50.97%)\n",
            "TN: 260 (16.86%)\n",
            "New best val_F1: 0.5058 (model saved, threshold=0.3176)\n",
            "[15/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 15 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 15 train: 100%|██████████| 225/225 [00:48<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6936, train acc: 50.71%, train F1(pos=0): 0.5126\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1865 1772]\n",
            " [1774 1783]]\n",
            "TP: 1865 (25.92%)\n",
            "FN: 1772 (24.63%)\n",
            "FP: 1774 (24.66%)\n",
            "TN: 1783 (24.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 15): 0.3293\n",
            "val loss: 0.7001, val acc: 42.87%, val F1(pos=0): 0.5064\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[452  44]\n",
            " [837 209]]\n",
            "TP: 452 (29.31%)\n",
            "FN: 44 (2.85%)\n",
            "FP: 837 (54.28%)\n",
            "TN: 209 (13.55%)\n",
            "New best val_F1: 0.5064 (model saved, threshold=0.3293)\n",
            "[16/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 16 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 16 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6929, train acc: 51.85%, train F1(pos=0): 0.4912\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1672 1888]\n",
            " [1576 2058]]\n",
            "TP: 1672 (23.24%)\n",
            "FN: 1888 (26.24%)\n",
            "FP: 1576 (21.91%)\n",
            "TN: 2058 (28.61%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 16): 0.3364\n",
            "val loss: 0.7060, val acc: 44.42%, val F1(pos=0): 0.5078\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[442  54]\n",
            " [803 243]]\n",
            "TP: 442 (28.66%)\n",
            "FN: 54 (3.50%)\n",
            "FP: 803 (52.08%)\n",
            "TN: 243 (15.76%)\n",
            "New best val_F1: 0.5078 (model saved, threshold=0.3364)\n",
            "[17/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 17 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 17 train: 100%|██████████| 225/225 [00:48<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6927, train acc: 52.17%, train F1(pos=0): 0.4934\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1676 1914]\n",
            " [1527 2077]]\n",
            "TP: 1676 (23.30%)\n",
            "FN: 1914 (26.61%)\n",
            "FP: 1527 (21.23%)\n",
            "TN: 2077 (28.87%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 17): 0.3020\n",
            "val loss: 0.6810, val acc: 48.96%, val F1(pos=0): 0.5133\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[415  81]\n",
            " [706 340]]\n",
            "TP: 415 (26.91%)\n",
            "FN: 81 (5.25%)\n",
            "FP: 706 (45.78%)\n",
            "TN: 340 (22.05%)\n",
            "New best val_F1: 0.5133 (model saved, threshold=0.3020)\n",
            "[18/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 18 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 18 train: 100%|██████████| 225/225 [00:48<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6917, train acc: 52.27%, train F1(pos=0): 0.5122\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1803 1803]\n",
            " [1631 1957]]\n",
            "TP: 1803 (25.06%)\n",
            "FN: 1803 (25.06%)\n",
            "FP: 1631 (22.67%)\n",
            "TN: 1957 (27.20%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 18): 0.3340\n",
            "val loss: 0.7033, val acc: 32.17%, val F1(pos=0): 0.4868\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1046    0]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1046 (67.83%)\n",
            "TN: 0 (0.00%)\n",
            "[19/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 19 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 19 train: 100%|██████████| 225/225 [00:48<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6945, train acc: 49.78%, train F1(pos=0): 0.5068\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1856 1755]\n",
            " [1858 1725]]\n",
            "TP: 1856 (25.80%)\n",
            "FN: 1755 (24.40%)\n",
            "FP: 1858 (25.83%)\n",
            "TN: 1725 (23.98%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 19): 0.3447\n",
            "val loss: 0.7116, val acc: 32.17%, val F1(pos=0): 0.4868\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1046    0]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1046 (67.83%)\n",
            "TN: 0 (0.00%)\n",
            "[20/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 20 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 20 train: 100%|██████████| 225/225 [00:48<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6939, train acc: 49.72%, train F1(pos=0): 0.4565\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1519 2022]\n",
            " [1595 2058]]\n",
            "TP: 1519 (21.11%)\n",
            "FN: 2022 (28.11%)\n",
            "FP: 1595 (22.17%)\n",
            "TN: 2058 (28.61%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 20): 0.3267\n",
            "val loss: 0.6972, val acc: 32.17%, val F1(pos=0): 0.4868\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[ 496    0]\n",
            " [1046    0]]\n",
            "TP: 496 (32.17%)\n",
            "FN: 0 (0.00%)\n",
            "FP: 1046 (67.83%)\n",
            "TN: 0 (0.00%)\n",
            "[21/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 21 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 21 train: 100%|██████████| 225/225 [00:48<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6928, train acc: 51.82%, train F1(pos=0): 0.4853\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1634 1962]\n",
            " [1504 2094]]\n",
            "TP: 1634 (22.71%)\n",
            "FN: 1962 (27.27%)\n",
            "FP: 1504 (20.91%)\n",
            "TN: 2094 (29.11%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 21): 0.3281\n",
            "val loss: 0.6981, val acc: 50.19%, val F1(pos=0): 0.5152\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[408  88]\n",
            " [680 366]]\n",
            "TP: 408 (26.46%)\n",
            "FN: 88 (5.71%)\n",
            "FP: 680 (44.10%)\n",
            "TN: 366 (23.74%)\n",
            "New best val_F1: 0.5152 (model saved, threshold=0.3281)\n",
            "[22/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 22 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 22 train: 100%|██████████| 225/225 [00:48<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6913, train acc: 53.95%, train F1(pos=0): 0.5261\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1839 1741]\n",
            " [1572 2042]]\n",
            "TP: 1839 (25.56%)\n",
            "FN: 1741 (24.20%)\n",
            "FP: 1572 (21.85%)\n",
            "TN: 2042 (28.38%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 22): 0.3054\n",
            "val loss: 0.6885, val acc: 47.02%, val F1(pos=0): 0.5146\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[433  63]\n",
            " [754 292]]\n",
            "TP: 433 (28.08%)\n",
            "FN: 63 (4.09%)\n",
            "FP: 754 (48.90%)\n",
            "TN: 292 (18.94%)\n",
            "[23/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 23 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 23 train: 100%|██████████| 225/225 [00:48<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6902, train acc: 54.78%, train F1(pos=0): 0.5711\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2166 1478]\n",
            " [1775 1775]]\n",
            "TP: 2166 (30.11%)\n",
            "FN: 1478 (20.54%)\n",
            "FP: 1775 (24.67%)\n",
            "TN: 1775 (24.67%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 23): 0.3225\n",
            "val loss: 0.6962, val acc: 47.99%, val F1(pos=0): 0.5139\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[424  72]\n",
            " [730 316]]\n",
            "TP: 424 (27.50%)\n",
            "FN: 72 (4.67%)\n",
            "FP: 730 (47.34%)\n",
            "TN: 316 (20.49%)\n",
            "[24/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 24 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 24 train: 100%|██████████| 225/225 [00:48<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6896, train acc: 54.78%, train F1(pos=0): 0.5668\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2128 1517]\n",
            " [1736 1813]]\n",
            "TP: 2128 (29.58%)\n",
            "FN: 1517 (21.09%)\n",
            "FP: 1736 (24.13%)\n",
            "TN: 1813 (25.20%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 24): 0.2849\n",
            "val loss: 0.6806, val acc: 45.20%, val F1(pos=0): 0.5135\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[446  50]\n",
            " [795 251]]\n",
            "TP: 446 (28.92%)\n",
            "FN: 50 (3.24%)\n",
            "FP: 795 (51.56%)\n",
            "TN: 251 (16.28%)\n",
            "[25/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 25 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 25 train: 100%|██████████| 225/225 [00:48<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6897, train acc: 55.10%, train F1(pos=0): 0.5309\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1828 1731]\n",
            " [1499 2136]]\n",
            "TP: 1828 (25.41%)\n",
            "FN: 1731 (24.06%)\n",
            "FP: 1499 (20.84%)\n",
            "TN: 2136 (29.69%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 25): 0.3223\n",
            "val loss: 0.6929, val acc: 53.57%, val F1(pos=0): 0.5123\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[376 120]\n",
            " [596 450]]\n",
            "TP: 376 (24.38%)\n",
            "FN: 120 (7.78%)\n",
            "FP: 596 (38.65%)\n",
            "TN: 450 (29.18%)\n",
            "[26/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 26 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 26 train: 100%|██████████| 225/225 [00:48<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6881, train acc: 55.77%, train F1(pos=0): 0.5283\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1782 1772]\n",
            " [1410 2230]]\n",
            "TP: 1782 (24.77%)\n",
            "FN: 1772 (24.63%)\n",
            "FP: 1410 (19.60%)\n",
            "TN: 2230 (31.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 26): 0.3230\n",
            "val loss: 0.7067, val acc: 45.07%, val F1(pos=0): 0.5118\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[444  52]\n",
            " [795 251]]\n",
            "TP: 444 (28.79%)\n",
            "FN: 52 (3.37%)\n",
            "FP: 795 (51.56%)\n",
            "TN: 251 (16.28%)\n",
            "[27/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 27 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 27 train: 100%|██████████| 225/225 [00:48<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6885, train acc: 55.25%, train F1(pos=0): 0.5729\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2159 1444]\n",
            " [1775 1816]]\n",
            "TP: 2159 (30.01%)\n",
            "FN: 1444 (20.07%)\n",
            "FP: 1775 (24.67%)\n",
            "TN: 1816 (25.24%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 27): 0.2812\n",
            "val loss: 0.6746, val acc: 46.24%, val F1(pos=0): 0.5172\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[444  52]\n",
            " [777 269]]\n",
            "TP: 444 (28.79%)\n",
            "FN: 52 (3.37%)\n",
            "FP: 777 (50.39%)\n",
            "TN: 269 (17.44%)\n",
            "New best val_F1: 0.5172 (model saved, threshold=0.2812)\n",
            "[28/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 28 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 28 train: 100%|██████████| 225/225 [00:48<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6892, train acc: 55.05%, train F1(pos=0): 0.5372\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1877 1717]\n",
            " [1517 2083]]\n",
            "TP: 1877 (26.09%)\n",
            "FN: 1717 (23.87%)\n",
            "FP: 1517 (21.09%)\n",
            "TN: 2083 (28.95%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 28): 0.3713\n",
            "val loss: 0.7307, val acc: 52.14%, val F1(pos=0): 0.5132\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[389 107]\n",
            " [631 415]]\n",
            "TP: 389 (25.23%)\n",
            "FN: 107 (6.94%)\n",
            "FP: 631 (40.92%)\n",
            "TN: 415 (26.91%)\n",
            "[29/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 29 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 29 train: 100%|██████████| 225/225 [00:48<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6903, train acc: 53.84%, train F1(pos=0): 0.5528\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[2053 1527]\n",
            " [1794 1820]]\n",
            "TP: 2053 (28.54%)\n",
            "FN: 1527 (21.23%)\n",
            "FP: 1794 (24.94%)\n",
            "TN: 1820 (25.30%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 29): 0.3271\n",
            "val loss: 0.6984, val acc: 55.45%, val F1(pos=0): 0.5213\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[374 122]\n",
            " [565 481]]\n",
            "TP: 374 (24.25%)\n",
            "FN: 122 (7.91%)\n",
            "FP: 565 (36.64%)\n",
            "TN: 481 (31.19%)\n",
            "New best val_F1: 0.5213 (model saved, threshold=0.3271)\n",
            "[30/30] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 30 train:   0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # 16bit浮動小数点で計算、必要な部分のみ32bit\n",
            "Epoch 30 train: 100%|██████████| 225/225 [00:48<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.6889, train acc: 55.70%, train F1(pos=0): 0.5444\n",
            "Train confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[1904 1655]\n",
            " [1532 2103]]\n",
            "TP: 1904 (26.47%)\n",
            "FN: 1655 (23.01%)\n",
            "FP: 1532 (21.30%)\n",
            "TN: 2103 (29.23%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:   0%|          | 0/49 [00:00<?, ?it/s]/tmp/ipython-input-1460929786.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validation: 100%|██████████| 49/49 [00:03<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best threshold (epoch 30): 0.2637\n",
            "val loss: 0.6596, val acc: 50.91%, val F1(pos=0): 0.5194\n",
            "Validation confusion (epoch):\n",
            "Confusion matrix (rows=true, cols=pred) with label order: ['above', 'below']\n",
            "[[409  87]\n",
            " [670 376]]\n",
            "TP: 409 (26.52%)\n",
            "FN: 87 (5.64%)\n",
            "FP: 670 (43.45%)\n",
            "TN: 376 (24.38%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 49/49 [00:36<00:00,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7000, Test acc%: 53.76%, Test acc: 0.5376\n",
            "Test F1 (pos=0) using threshold 0.3271 F1: 0.5120\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}